{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3b3809-5338-4f96-8be7-9135b898ed3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea88c512-2161-4746-aaca-7197487c8e3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ba9a5c7-1e25-456d-a5ba-0d8f103f123d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 1s 60ms/step - loss: 1024.6816 - val_loss: 273.7853\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 278.5581 - val_loss: 208.6237\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 181.5950 - val_loss: 125.7610\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 162.1156 - val_loss: 74.8452\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 105.2366 - val_loss: 74.4359\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 72.5958 - val_loss: 126.6922\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 53.3616 - val_loss: 50.4831\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 35.6386 - val_loss: 47.0732\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 22.6804 - val_loss: 44.4999\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 11.0238 - val_loss: 35.9750\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import tkinter as tk\n",
    "import re\n",
    "from tkinter import filedialog, messagebox\n",
    "from plotly import graph_objects as go\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to extract features from an image using SIFT\n",
    "def extract_features(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "# Function to match features between two images using Brute-Force matcher\n",
    "def match_features(descriptors1, descriptors2):\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_L2)\n",
    "    if descriptors1.dtype != descriptors2.dtype:\n",
    "        descriptors2 = descriptors2.astype(descriptors1.dtype)\n",
    "    matches = matcher.match(descriptors1, descriptors2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    return matches\n",
    "\n",
    "# Function to estimate the alignment parameters (translation) from matched keypoints\n",
    "def estimate_alignment(matches, keypoints1, keypoints2):\n",
    "    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    dx = M[0, 2]\n",
    "    dy = M[1, 2]\n",
    "    return dx, dy\n",
    "\n",
    "# Function to train a regression model on alignment parameters\n",
    "def train_model(features, alignment_parameters, model=None):\n",
    "    if model is None:\n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Dense(32, activation='relu', input_shape=(len(features[0]),)),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(2)  # Two outputs: dx and dy\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(features, alignment_parameters, test_size=0.2, random_state=42)\n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=16)\n",
    "    return model, history\n",
    "\n",
    "# Function to select the folder using Tkinter\n",
    "def select_folder():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    folder_selected = filedialog.askdirectory(title='Select Input Folder')\n",
    "    root.destroy()  # Destroy the root window\n",
    "    return folder_selected\n",
    "\n",
    "def select_model_file():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    file_path = filedialog.askopenfilename(title='Select Model File', filetypes=[('Model Files', '*.h5')])\n",
    "    root.destroy()  # Destroy the root window\n",
    "    return file_path\n",
    "\n",
    "def select_output_folder():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    folder_selected = filedialog.askdirectory(title='Select Output Folder for Training Report')\n",
    "    root.destroy()  # Destroy the root window\n",
    "    return folder_selected\n",
    "\n",
    "# Function to display the training and validation plot\n",
    "def display_training_plot(history):\n",
    "    plot_metrics(history)\n",
    "\n",
    "# Function to log the training metrics to a file\n",
    "def log_metrics(metrics, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write('Training Metrics:\\n')\n",
    "        for metric_name, metric_values in metrics.items():\n",
    "            f.write(f'{metric_name}: {metric_values}\\n')\n",
    "\n",
    "# Function to plot the training metrics\n",
    "def plot_metrics(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history.get('val_loss', [])\n",
    "    epochs = list(range(1, len(loss) + 1))  # Convert epochs to a list\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=epochs, y=loss, name='Training Loss'))\n",
    "    fig.add_trace(go.Scatter(x=epochs, y=val_loss, name='Validation Loss'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Training Metrics',\n",
    "        xaxis_title='Epochs',\n",
    "        yaxis_title='Loss',\n",
    "        xaxis=dict(title='Epochs'),\n",
    "        yaxis=dict(title='Loss'),\n",
    "        xaxis_tickmode='linear',\n",
    "        xaxis_dtick=1  # Increase the granularity of x-axis ticks\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(showline=True, linewidth=1, linecolor='black')  # Add axis line\n",
    "    fig.update_yaxes(showline=True, linewidth=1, linecolor='black')\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Function to continue training on an existing model\n",
    "def continue_training_model(features, alignment_parameters, model):\n",
    "    # Adjust the input shape of the model if needed\n",
    "    if model.input_shape[1] != features.shape[1]:\n",
    "        model = adjust_model_input_shape(model, features.shape[1])\n",
    "\n",
    "    history = model.fit(features, alignment_parameters, epochs=10, batch_size=16)\n",
    "    return model, history\n",
    "\n",
    "def adjust_model_input_shape(model, new_input_shape):\n",
    "    # Create a new model with adjusted input shape\n",
    "    new_model = tf.keras.Sequential()\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, layers.Dense):\n",
    "            new_layer = layers.Dense(layer.units, activation=layer.activation, input_shape=(new_input_shape,))\n",
    "        else:\n",
    "            new_layer = layer\n",
    "        new_model.add(new_layer)\n",
    "    new_model.compile(optimizer=model.optimizer, loss=model.loss)\n",
    "    return new_model\n",
    "\n",
    "# Function to run alignment using an existing model\n",
    "def run_alignment_model(image_files, input_folder, ideal_image, model, training_report_folder):\n",
    "    keypoints_ideal, descriptors_ideal = extract_features(ideal_image)\n",
    "\n",
    "    if descriptors_ideal is None:\n",
    "        failed_images_feature_extraction = [image_files[0]]  # Add the ideal image to the list of failed feature extraction\n",
    "    else:\n",
    "        failed_images_feature_extraction = []  # Initialize the list of images with failed feature extraction\n",
    "\n",
    "    # Perform alignment for each image\n",
    "    alignment_distances = []  # Initialize the alignment distances list\n",
    "    for image_file in image_files:\n",
    "        image = cv2.imread(os.path.join(input_folder, image_file))\n",
    "        keypoints, descriptors = extract_features(image)\n",
    "\n",
    "        if descriptors is None:\n",
    "            failed_images_feature_extraction.append(image_file)  # Add the image filename to the list of failed feature extraction\n",
    "            continue\n",
    "\n",
    "        matches = match_features(descriptors_ideal, descriptors)\n",
    "\n",
    "        if matches is None:\n",
    "            failed_images_feature_extraction.append(image_file)  # Add the image filename to the list of failed feature extraction\n",
    "            continue\n",
    "\n",
    "        dx, dy = estimate_alignment(matches, keypoints_ideal, keypoints)\n",
    "        distance = np.sqrt(dx ** 2 + dy ** 2)\n",
    "        alignment_distances.append((image_file, dx, dy, distance))\n",
    "\n",
    "        # Draw aligned images and save them\n",
    "        aligned_image_file = os.path.join(training_report_folder, f'aligned_image_{image_file}')\n",
    "        feature_image = cv2.drawKeypoints(image, keypoints, None, color=(0, 0, 255), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        cv2.imwrite(aligned_image_file, feature_image)\n",
    "\n",
    "    # Sort the alignment distances numerically based on the image file name\n",
    "    alignment_distances.sort(key=lambda x: int(re.search(r'\\d+', x[0]).group()) if re.search(r'\\d+', x[0]) else float('inf'))\n",
    "\n",
    "    # Save alignment distances to the ideal image in the training report\n",
    "    with open(os.path.join(training_report_folder, 'alignment_distances.txt'), 'w') as f:\n",
    "        f.write('Alignment Distances to Ideal Image:\\n')\n",
    "        for image_file, dx, dy, distance in alignment_distances:\n",
    "            f.write(f'{image_file}: x: {dx}, y: {dy}, total: {distance}\\n')\n",
    "\n",
    "    # Update the training report with the failed images for feature extraction\n",
    "    with open(os.path.join(training_report_folder, 'training_report.txt'), 'w') as f:\n",
    "        num_failed_images = len(failed_images_feature_extraction)\n",
    "        num_accurately_aligned_images = len(alignment_distances) - num_failed_images\n",
    "        f.write(f'Number of Accurately Aligned Images: {num_accurately_aligned_images}\\n')\n",
    "        f.write('Images with Failed Feature Extraction:\\n')\n",
    "        for image_file in failed_images_feature_extraction:\n",
    "            f.write(f'{image_file}\\n')\n",
    "\n",
    "    # Calculate alignment success rate\n",
    "    total_images = len(image_files) - 1  # Excluding the ideal image\n",
    "    alignment_success_rate = (num_accurately_aligned_images / total_images) * 100\n",
    "\n",
    "    # Update the training report with the alignment success rate\n",
    "    with open(os.path.join(training_report_folder, 'training_report.txt'), 'a') as f:\n",
    "        f.write(f'Alignment Success Rate: {alignment_success_rate:.2f}%\\n')\n",
    "\n",
    "    messagebox.showinfo('Training Complete', 'Evaluation complete! Check the training report for details.')\n",
    "\n",
    "# Main script\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "input_folder = select_folder()\n",
    "if input_folder is not None:\n",
    "    features = []\n",
    "    alignment_parameters = []\n",
    "    failed_feature_extraction_images = []  # List to store images with failed feature extraction\n",
    "\n",
    "    # Find the ideal image with '_ideal' in the filename\n",
    "    image_files = sorted([filename for filename in os.listdir(input_folder) if filename.endswith('.png')])\n",
    "    for filename in image_files:\n",
    "        if '_ideal' in filename:\n",
    "            ideal_image = cv2.imread(os.path.join(input_folder, filename))\n",
    "            break\n",
    "\n",
    "    # Read training images and extract features and alignment parameters\n",
    "    for filename in image_files:\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        keypoints_auto, descriptors_auto = extract_features(image)\n",
    "\n",
    "        if descriptors_auto is not None:\n",
    "            features.append(descriptors_auto.flatten())\n",
    "            dx, dy = get_alignment_parameters()  # Function to get alignment parameters\n",
    "            alignment_parameters.append([dx, dy])\n",
    "        else:\n",
    "            failed_feature_extraction_images.append(filename)  # Store the image with failed feature extraction\n",
    "\n",
    "    # Check if any training images were successfully processed\n",
    "    if len(features) == 0:\n",
    "        messagebox.showerror('No Training Images', 'No training images found or feature extraction failed for all images. Cannot proceed with training.')\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Determine the maximum length of feature vectors\n",
    "    max_length = max(len(feature) for feature in features)\n",
    "\n",
    "    # Pad shorter feature vectors with zeros\n",
    "    padded_features = []\n",
    "    for feature in features:\n",
    "        padded_feature = np.pad(feature, (0, max_length - len(feature)), mode='constant')\n",
    "        padded_features.append(padded_feature)\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    features = np.array(padded_features)\n",
    "    alignment_parameters = np.array(alignment_parameters)\n",
    "\n",
    "    # Select the output folder for saving the training report\n",
    "    training_report_folder = select_output_folder()\n",
    "\n",
    "    # Main script\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "\n",
    "    choice = messagebox.askquestion('Model Selection', 'Do you want to load an existing model?')\n",
    "\n",
    "    if choice == 'yes':\n",
    "        model_file = select_model_file()\n",
    "        model = tf.keras.models.load_model(model_file)\n",
    "\n",
    "        continue_training_choice = messagebox.askquestion('Model Usage', 'Do you want to continue training on the old model?')\n",
    "\n",
    "        if continue_training_choice == 'yes':\n",
    "            # Continue training on the existing model\n",
    "            model, history = continue_training_model(features, alignment_parameters, model)\n",
    "            display_training_plot(history)  # Display the training and validation plot\n",
    "            save_choice = messagebox.askquestion('Save Model', 'Do you want to save the trained model?')\n",
    "            if save_choice == 'yes':\n",
    "                model_path = filedialog.asksaveasfilename(title='Save Trained Model',\n",
    "                                                          defaultextension='.h5',\n",
    "                                                          filetypes=[('Model Files', '*.h5')])\n",
    "                model.save(model_path)\n",
    "        else:\n",
    "            # Run alignment using the existing model\n",
    "            run_alignment_model(image_files, input_folder, ideal_image, model, training_report_folder)\n",
    "    else:\n",
    "        # Create a new model and perform training\n",
    "        model = None\n",
    "\n",
    "        # Train the regression model\n",
    "        model, history = train_model(features, alignment_parameters, model)\n",
    "\n",
    "        # Save the trained model\n",
    "        save_choice = messagebox.askquestion('Save Model', 'Do you want to save the trained model?')\n",
    "        if save_choice == 'yes':\n",
    "            model_path = filedialog.asksaveasfilename(title='Save Trained Model',\n",
    "                                                      defaultextension='.h5',\n",
    "                                                      filetypes=[('Model Files', '*.h5')])\n",
    "            model.save(model_path)\n",
    "\n",
    "        # Log and save the training metrics\n",
    "        training_metrics = {\n",
    "            'Loss': history.history['loss'],\n",
    "            'Validation Loss': history.history.get('val_loss', [])\n",
    "        }\n",
    "        log_metrics(training_metrics, os.path.join(training_report_folder, 'training_metrics.txt'))\n",
    "\n",
    "        # Update the alignment process if an ideal image is selected\n",
    "        if ideal_image is not None:\n",
    "            run_alignment_model(image_files, input_folder, ideal_image, model, training_report_folder)\n",
    "\n",
    "    messagebox.showinfo('Training Complete', 'Training and evaluation complete! Check the training report for details.')\n",
    "    root.destroy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7c3c27-7a46-48a5-bcb5-88472ab6e614",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d43fa68-1a17-4ca6-9a3e-f646050183d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af5244-4d7e-4489-8dc0-49cf3e6836ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8940a07e-c726-4c26-b658-55183dbe1971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
